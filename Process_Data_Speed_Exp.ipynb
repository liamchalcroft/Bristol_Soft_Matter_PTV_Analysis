{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and set up\n",
    "\n",
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "from IPython.display import display\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from process_pickle import process_pickle\n",
    "from process_pickle_quiver import process_pickle_quiver\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed #Sliders for image selection\n",
    "import ipywidgets as widgets\n",
    "mpl.rc('figure',  figsize=(4.77, 2.95))\n",
    "mpl.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "mpl.rcParams['lines.linewidth'] = 0.6\n",
    "mpl.rcParams['lines.color'] = 'r'\n",
    "plt.rc('grid', linestyle=\"--\", color='gray')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  \n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that is called to configure how plots are to be drawn\n",
    "\n",
    "def setup_plot():\n",
    "    ax = plt.gca()\n",
    "    SPINE_COLOR = 'gray'\n",
    "    for spine in ['top', 'right']:\n",
    "            ax.spines[spine].set_visible(False)\n",
    "\n",
    "    for spine in ['left', 'bottom']:\n",
    "        ax.spines[spine].set_color(SPINE_COLOR)\n",
    "        ax.spines[spine].set_linewidth(0.5)\n",
    "\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n",
    "    plt.grid()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(4.77, 2.95, forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the file picker to locate the .pkl containing the particle trajectories\n",
    "\n",
    "or select a previously output .xlsx to skip the calculations\n",
    "\n",
    "**If it doesn't appear you probably need to minimise your browser or alt tab around for it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_custom_data_directory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the .pkl files you wish to analyse. When you're done selecting cancel should\n",
    "# allow you to continue to the next cell.\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "pkl_to_process = []\n",
    "file_path = \"1\"\n",
    "while len(file_path) != 0:\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if len(file_path) != 0:\n",
    "        pkl_to_process.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/liamchalcroft/Python/25C 1_8gL data first 1000 frames/trajectories.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm you've selected the correct files\n",
    "\n",
    "pkl_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liamchalcroft/Python/25C 1_8gL data first 1000 frames/trajectories.pkl\n",
      "Setting Parameters...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many frames to look back for velocity calculations?  25\n",
      "Enter NEXT to move to next pkl, anything else to add another analysis run for the current particle NEXT\n"
     ]
    }
   ],
   "source": [
    "# configure the calculations to be carried out on the data contained in the .pkl files\n",
    "# if you don't enter \"NEXT\" at the end you can queue another set of calculations to be carried out on the \n",
    "# same .pkl, e.g with a frame lookback.\n",
    "pkl_param = []\n",
    "\n",
    "i = 0\n",
    "mpp = 15 # microns per pixel\n",
    "timestep = 30 # seconds between images\n",
    "\n",
    "while i < len(pkl_to_process):\n",
    "    print(pkl_to_process[i])\n",
    "    print(\"Setting Parameters...\")\n",
    "    # uncomment the below lines to set mpp or timestep on a per .pkl basis\n",
    "    #mpp = int(input(\"Microns per Pixel: \"))\n",
    "    #timestep = int(input(\"Time between frames in seconds: \"))\n",
    "    frame_lookback = int(input(\"How many frames to look back for velocity calculations? \"))\n",
    "    pkl_param.append([i,mpp,timestep,frame_lookback])\n",
    "    move_next = input(\"Enter NEXT to move to next pkl, anything else to add another analysis run for the current particle\")\n",
    "    if move_next == \"NEXT\":\n",
    "        i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 15, 30, 25]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for the sets of calculations you've requested, select folders to store the results for each set in.\n",
    "\n",
    "data_dirs = []\n",
    "data_dir = True\n",
    "counter = 0\n",
    "for i in pkl_param:\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    data_dir = filedialog.askdirectory(title=\"Pick data dir for {} {}\".format(pkl_to_process[i[0]], i[3]))\n",
    "    data_dirs.append(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the folders you've requested the results stored in don't exist, make them:\n",
    "\n",
    "for directory in data_dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Calculating Displacement for particles: 100.00%\n",
      "\n",
      " Calculating Velocity for particle: 100.00%\n",
      "\n",
      " Calculating Y Velocity for particle: 100.00%\n",
      "\n",
      " Calculating X Velocity for particle: 100.00%\n",
      "\n",
      "Storing data...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "\n",
    "for c, param in enumerate(pkl_param):\n",
    "    # the process_pickle_quiver function is contained within a separate file - process_pickle_quiver.py\n",
    "    df = process_pickle_quiver(pkl_to_process[param[0]], data_dirs[c], param[1], param[2], param[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function called to draw the charts of the results\n",
    "\n",
    "def produce_charts(df, general_directory):\n",
    "    if not os.path.exists(general_directory + \"/figures\"):\n",
    "        os.makedirs(general_directory + \"/figures\")\n",
    "    no_bins = df.bin.max() + 1    \n",
    "    av_disp_by_frame = df.groupby('frame').displacement.mean().sort_index()\n",
    "    xs = av_disp_by_frame.index.values\n",
    "    ys = av_disp_by_frame.values\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.plot(xs, ys)\n",
    "    plt.ylabel(\"Displacement / px\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(general_directory + \"/figures/Average_displacement.pdf\")\n",
    "    fig = plt.gcf()\n",
    "\n",
    "\n",
    "    disp_vels = df.groupby('particle').velocity.mean()\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.xlabel(\"Velocity / ms$^-1$\")\n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "    plt.hist(disp_vels, bins=20)\n",
    "    plt.savefig(general_directory + \"/figures/Velocity Distribution by Displacement.pdf\")\n",
    "\n",
    "\n",
    "    y_vels = df.groupby('particle').y_velocity.mean()\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.xlabel(\"Velocity / ms$^-1$\")\n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "    plt.hist(y_vels, bins=20)\n",
    "    plt.savefig(general_directory + \"/figures/Velocity Distribution by Y Velocity.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "    av_vel_by_frame = df.groupby('frame').velocity.mean().sort_index()\n",
    "    xs = av_vel_by_frame.index.values\n",
    "    ys = av_vel_by_frame.values\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "    plt.ylabel(\"Velocity / ms$^-1$\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.autoscale(True)\n",
    "    plt.tight_layout()\n",
    "    plt.plot(xs, ys,)\n",
    "    plt.savefig(general_directory + \"/figures/Average_Velocity by Displacement.pdf\")\n",
    "\n",
    "    av_vel_by_frame = df.groupby('frame').y_velocity.mean().sort_index()\n",
    "    xs = av_vel_by_frame.index.values\n",
    "    ys = av_vel_by_frame.values\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "    plt.ylabel(\"Velocity / ms$^-1$\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.autoscale(True)\n",
    "    plt.plot(xs, ys)\n",
    "    plt.savefig(general_directory + \"/figures/Average_Velocity by Y Position.pdf\")\n",
    "    \n",
    "    av_vel_by_frame = df.groupby('frame').x_velocity.mean().sort_index()\n",
    "    xs = av_vel_by_frame.index.values\n",
    "    ys = av_vel_by_frame.values\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "    plt.ylabel(\"Velocity / ms$^-1$\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.autoscale(True)\n",
    "    plt.tight_layout()\n",
    "    plt.plot(xs, ys)\n",
    "    plt.savefig(general_directory + \"/figures/Average_Velocity by X Position.pdf\")\n",
    "    \n",
    "    av_vel_by_frame = df.groupby('frame').hyp_vel.mean().sort_index()\n",
    "    xs = av_vel_by_frame.index.values\n",
    "    ys = av_vel_by_frame.values\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.autoscale(enable=True, axis='both', tight=True)\n",
    "    plt.ylabel(\"Velocity / ms$^-1$\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.autoscale(True)\n",
    "    plt.tight_layout()\n",
    "    plt.plot(xs, ys)\n",
    "\n",
    "    plt.savefig(general_directory + \"/figures/Average_Velocity.pdf\")\n",
    "\n",
    "    spacings = []\n",
    "    for x in df.frame.unique():\n",
    "        w_df = df[df['frame']==x]\n",
    "        spacings.append(tp.proximity(w_df)['proximity'].mean())\n",
    "    plt.figure()\n",
    "    setup_plot()\n",
    "    plt.ylabel(\"Distance / px\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.plot(spacings)\n",
    "    plt.savefig(general_directory + \"/figures/nearest_neighbour.pdf\")\n",
    "\n",
    "    bin_vels = df.groupby('bin').hyp_vel.mean()\n",
    "    plt.figure()\n",
    "    bin_vels_to_plot = []\n",
    "    for c, v in enumerate(bin_vels):\n",
    "        bin_vels_to_plot.append((c, v))\n",
    "\n",
    "    err = df.groupby('bin').hyp_vel.std()\n",
    "    x = [x[0] for x in bin_vels_to_plot]\n",
    "    y = [x[1] for x in bin_vels_to_plot]\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    setup_plot()\n",
    "    plt.ylabel(\"Velocity / ms$^-1$\")\n",
    "    plt.xlabel(\"x position (\" + str(no_bins) +\" equally spaced bins)\")\n",
    "    plt.tight_layout()\n",
    "    plt.bar(x, y, yerr = err, error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "\n",
    "    plt.savefig(general_directory + \"/figures/x_binned_velocity.pdf\")\n",
    "    \n",
    "    bin_vels = df.groupby('bin').y_velocity.mean()\n",
    "    plt.figure()\n",
    "    bin_vels_to_plot = []\n",
    "    for c, v in enumerate(bin_vels):\n",
    "        bin_vels_to_plot.append((c, v))\n",
    "\n",
    "    err = df.groupby('bin').y_velocity.std()\n",
    "    x = [x[0] for x in bin_vels_to_plot]\n",
    "    y = [x[1] for x in bin_vels_to_plot]\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    setup_plot()\n",
    "    plt.ylabel(\"Velocity / ms$^-1$\")\n",
    "    plt.xlabel(\"x position (\" + str(no_bins) +\" equally spaced bins)\")\n",
    "    plt.tight_layout()\n",
    "    plt.bar(x, y, yerr = err, error_kw=dict(elinewidth=2,ecolor='black'))\n",
    "\n",
    "    plt.savefig(general_directory + \"/figures/x_binned_y_velocity.pdf\")\n",
    "    \n",
    "    \n",
    "\n",
    "    def x_hist(frame):\n",
    "        w_df = df[df.frame == frame].copy()\n",
    "        bin_vels = w_df.groupby('bin').hyp_vel.mean()\n",
    "        plt.figure()\n",
    "        bin_vels_to_plot = []\n",
    "        for c, v in enumerate(bin_vels):\n",
    "            bin_vels_to_plot.append((c, v))\n",
    "        x = [x[0] for x in bin_vels_to_plot]\n",
    "        y = [x[1] for x in bin_vels_to_plot]\n",
    "        plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "        setup_plot()\n",
    "        plt.ylabel(\"Velocity / ms$^-1$\")\n",
    "        plt.xlabel(\"x position (\" + str(no_bins) +\" equally spaced bins)\")\n",
    "        plt.xlim(0, 20)\n",
    "        plt.bar(x, y)\n",
    "\n",
    "\n",
    "\n",
    "    ### Set use_y_vel_only to true to plot only the y component of the particles' velocities\n",
    "\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    use_y_vel_only = True\n",
    "\n",
    "    if use_y_vel_only:\n",
    "        a = df.groupby([(df.frame // 50) * 50 , 'bin']).y_velocity.mean().fillna(0)\n",
    "    else:\n",
    "        a = df.groupby([(df.frame // 50) * 50 , 'bin']).hyp_vel.mean().fillna(0)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    zs = []\n",
    "    xs = [x[1] for x in a.index.values]\n",
    "    zs = [x[0] for x in a.index.values]\n",
    "\n",
    "    for x in a:\n",
    "        ys.append(x * 1*10**6)  \n",
    "\n",
    "\n",
    "\n",
    "    colours_alt = []\n",
    "    options = ['r','g', 'b']\n",
    "    option_index = 0\n",
    "    prev_a = 99\n",
    "    for a in xs:\n",
    "        if a <= prev_a:\n",
    "            option_index += 1\n",
    "            if (option_index)  >= len(options):\n",
    "                option_index = 0\n",
    "        colours_alt.append(options[option_index])\n",
    "        prev_a = a  \n",
    "\n",
    "    r = 0.99\n",
    "    colours = []\n",
    "    add = r / len(xs)\n",
    "    for x in range(len(xs)):\n",
    "        colours.append((r, 0, 1 -r))\n",
    "        r -= add\n",
    "\n",
    "    %matplotlib inline\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.bar(xs, ys, zs=zs, zdir = 'y', color = colours)\n",
    "    ax.set_xlabel('x bin')\n",
    "    ax.set_zlabel('Average velocity / um s-1')\n",
    "    ax.set_ylabel('Frame')\n",
    "    plt.show()\n",
    "    plt.savefig(general_directory + \"/figures/3d_bar_vel.pdf\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xs, zs, ys, color = colours)\n",
    "    ax.set_xlabel('x bin')\n",
    "    ax.set_zlabel('Average velocity / um s-1')\n",
    "    ax.set_ylabel('Frame')\n",
    "    plt.show() \n",
    "\n",
    "    ax = df.groupby('frame')['x'].count().plot()\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(general_directory + \"/figures/particles_in_frame.pdf\")\n",
    "\n",
    "for c, param in enumerate(pkl_param):\n",
    "    # the process_pickle function is contained within a separate file - process_pickle.py\n",
    "    df = process_pickle(pkl_to_process[param[0]], data_dirs[c], param[1], param[2], param[3])\n",
    "    print('Producing plots...')\n",
    "    print('\\n')\n",
    "    produce_charts(df, data_dirs[c])    \n",
    "    print('\\n')\n",
    "    print('Finished')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many frames per animation frame?  50\n"
     ]
    }
   ],
   "source": [
    "npstep = int(input('How many frames per animation frame? '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing data via pure numpy method: \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamchalcroft/opt/miniconda3/envs/uobenv/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value of array 4.742591904394578e-07\n",
      "\n",
      "\n",
      "Normalised velocity:  [[       nan        nan        nan ...        nan        nan        nan]\n",
      " [       nan        nan        nan ...        nan        nan        nan]\n",
      " [       nan        nan        nan ...        nan        nan        nan]\n",
      " ...\n",
      " [0.01585431 0.02445682 0.03895443 ...        nan        nan        nan]\n",
      " [0.0181034         nan 0.01766916 ...        nan        nan        nan]\n",
      " [0.02515695        nan 0.01915836 ...        nan        nan        nan]]\n",
      "0.03319009024136356\n",
      "nan\n",
      "Velocity vals:  [[       nan        nan        nan ...        nan        nan        nan]\n",
      " [       nan        nan        nan ...        nan        nan        nan]\n",
      " [       nan        nan        nan ...        nan        nan        nan]\n",
      " ...\n",
      " [0.01585431        nan        nan ...        nan        nan        nan]\n",
      " [0.0181034         nan        nan ...        nan        nan        nan]\n",
      " [0.02515695        nan 0.01915836 ...        nan        nan        nan]]\n",
      "3D vel shape:  (1001, 27, 11) 2D vel shape:  (1001, 298)\n",
      "Preview - velocity in frames 58-62: [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "shape x = (27, 11) shape y = (27, 11) shape x = (27, 11) shape v = (1001, 27, 11) shape vx = (1001, 27, 11) shape vy = (1001, 27, 11)\n",
      "Max velocity =  0\n",
      "\n",
      "\n",
      "All done. Now producing vector plots: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "And finally heatmap plots: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def df_to_numpy(general_directory):\n",
    "    xdf = pd.read_csv(general_directory + '/data_quiver.csv', usecols=[9, 10, 18])\n",
    "    xdf = xdf.reset_index().pivot_table(index='frame',\n",
    "                                       columns='particle',\n",
    "                                       aggfunc='mean').values\n",
    "    nofrm = len(xdf)\n",
    "    noprt = len(xdf[0])\n",
    "    \n",
    "    ydf = pd.read_csv(general_directory + '/data_quiver.csv', usecols=[9, 10, 19])\n",
    "    ydf = ydf.reset_index().pivot_table(index='frame',\n",
    "                                       columns='particle',\n",
    "                                       aggfunc='mean').values\n",
    "    \n",
    "    vdf = pd.read_csv(general_directory + '/data_quiver.csv', usecols=[9, 10, 17])\n",
    "    vdf = vdf.reset_index().pivot_table(index='frame',\n",
    "                                       columns='particle',\n",
    "                                       aggfunc='mean').values\n",
    "         \n",
    "    vdf[vdf>=1e-6] = np.nan\n",
    "\n",
    "    print('Max value of array', np.nanmax(vdf))\n",
    "    vmax = np.nanmax(vdf)\n",
    "    vdf = vdf/vmax\n",
    "    print('\\n')\n",
    "    print('Normalised velocity: ',vdf)\n",
    "    \n",
    "    print(vdf[30,0])\n",
    "    print(vdf[0,30])\n",
    "    \n",
    "    vxdf = pd.read_csv(general_directory + '/data_quiver.csv', usecols=[9, 10, 16])\n",
    "    vxdf = vxdf.reset_index().pivot_table(index='frame',\n",
    "                                       columns='particle',\n",
    "                                       aggfunc='mean').values\n",
    "    vxdf = vxdf/vmax\n",
    "\n",
    "    vydf = pd.read_csv(general_directory + '/data_quiver.csv', usecols=[9, 10, 15])\n",
    "    vydf = vydf.reset_index().pivot_table(index='frame',\n",
    "                                       columns='particle',\n",
    "                                       aggfunc='mean').values\n",
    "    vydf = vydf/vmax\n",
    "    \n",
    "    for p in range(1, noprt-1):\n",
    "        for f in range(0, nofrm-1):\n",
    "            if (f%npstep == 0):\n",
    "                xdf[f, p] = np.mean(xdf[f-npstep:f, p])\n",
    "                ydf[f, p] = np.mean(ydf[f-npstep:f, p])\n",
    "                vdf[f, p] = np.mean(vdf[f-npstep:f, p])\n",
    "                vxdf[f, p] = np.mean(vxdf[f-npstep:f, p])\n",
    "                vydf[f, p] = np.mean(vydf[f-npstep:f, p])\n",
    "            else:\n",
    "                xdf[f, p] = np.nan\n",
    "                ydf[f, p] = np.nan\n",
    "                vdf[f, p] = np.nan\n",
    "                vxdf[f, p] = np.nan\n",
    "                vydf[f, p] = np.nan\n",
    "                \n",
    "    for p in range(1, noprt-1): # set condition for if two particles are in the same co-ordinate\n",
    "        for p2 in range(1, noprt-1):\n",
    "            for f in range(0, nofrm-1, npstep):\n",
    "                n = 1\n",
    "                if xdf[f, p] == xdf[f, p2] and ydf[f, p] == ydf[f, p2]:\n",
    "                    vdf[f, p] += vdf[f, p2] # Append p2 to value of p\n",
    "                    vxdf[f, p] += vxdf[f, p2]\n",
    "                    vydf[f, p] += vydf[f, p2]\n",
    "\n",
    "                    xdf[f, p2] = np.nan # Set p2 to NaN to drop when back in dataframe\n",
    "                    ydf[f, p2] = np.nan\n",
    "                    vdf[f, p2] = np.nan\n",
    "                    vxdf[f, p2] = np.nan\n",
    "                    vydf[f, p2] = np.nan\n",
    "                    n += 1\n",
    "\n",
    "                vdf[f, p] = (vdf[f, p])/n # Average of variables in (x,y) co-ordinate\n",
    "                vxdf[f, p] = (vxdf[f, p])/n\n",
    "                vydf[f, p] = (vydf[f, p])/n\n",
    "    \n",
    "    print('Velocity vals: ',vdf)\n",
    "    xs = np.linspace(0, 500, 11)\n",
    "    ys = np.linspace(0,1300, 27)\n",
    "    xi,yi = np.meshgrid(xs, ys)\n",
    "    \n",
    "    v_vals = vx_vals = vy_vals = np.array([[[0 for col in range(11)] \n",
    "                                   for row in range(27)]\n",
    "                                  for x in range(nofrm)]) # 3D array of form array[f][x][yrame]\n",
    "    print('3D vel shape: ',v_vals.shape,'2D vel shape: ',vdf.shape)\n",
    "    for f in range(0, nofrm-1):\n",
    "        for p in range(1, noprt-1):\n",
    "            for x in range(0, 500, 50):\n",
    "                for y in range(0, 1300, 50):\n",
    "                    if ((np.isnan(vdf[f, p]) == False)\n",
    "                        and ((ydf[f, p]) == y)\n",
    "                        and ((xdf[f, p]) == x)):\n",
    "                            v_vals[f, x, y] = vdf[f, p]\n",
    "                            vx_vals[f, x, y] = vxdf[f, p]\n",
    "                            vy_vals[f, x, y] = vydf[f, p]\n",
    "    \n",
    "    print('Preview - velocity in frames 58-62:',v_vals[58:62,:,:])\n",
    "    print('shape x =',xi.shape,'shape y =',yi.shape,'shape x =',yi.shape,\n",
    "         'shape v =',v_vals.shape, 'shape vx =',vx_vals.shape, 'shape vy =',vy_vals.shape)\n",
    "    print('Max velocity = ',np.nanmax(v_vals))\n",
    "    print('\\n')\n",
    "    print('All done. Now producing vector plots: ')\n",
    "    print('\\n')    \n",
    "    \n",
    "    if not os.path.exists(general_directory + \"/vector_frames/\"):\n",
    "        os.makedirs(general_directory + \"/vector_frames/\")\n",
    "        \n",
    "    for i in range(0, nofrm-1, npstep): \n",
    "        \n",
    "        fig = plt.figure(figsize=(5,13))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.set_xlim(0, 500)\n",
    "        ax.set_ylim(0, 1300)\n",
    "        \n",
    "        v = v_vals[i,:,:]\n",
    "        vx = vx_vals[i,:,:]\n",
    "        vy = vy_vals[i,:,:]\n",
    "        \n",
    "        quiv = ax.quiver(xi, yi, vx, vy, [v], cmap='RdBu_r', headlength=3)\n",
    "        plt.title(\"t = \" + str(i) + \"s\")\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(quiv, cax=cax, orientation='vertical')\n",
    "        plt.savefig(general_directory + \"/vector_frames/vector_\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "        \n",
    "    vecim = []\n",
    "    for i in range(0, nofrm-1, npstep):\n",
    "        vecim.append(imageio.imread(general_directory + \"/vector_frames/vector_\"\n",
    "                                     + str(i) + \".png\"))\n",
    "    imageio.mimsave((general_directory + \"/vector_frames/vector.gif\"), vecim)\n",
    "\n",
    "    print('\\n')\n",
    "    print('And finally heatmap plots: ')\n",
    "    print('\\n')    \n",
    "    \n",
    "    if not os.path.exists(general_directory + \"/heatmap_frames/\"):\n",
    "        os.makedirs(general_directory + \"/heatmap_frames/\")\n",
    "\n",
    "    for i in range(0, nofrm-1, npstep): \n",
    "    \n",
    "        heatfig = plt.figure(figsize=(5,13))\n",
    "        axh = heatfig.add_subplot(1, 1, 1)\n",
    "        axh.set_xlim(0, 500)\n",
    "        axh.set_ylim(0, 1300)       \n",
    "        \n",
    "        im = plt.contourf(xi, yi, v_vals[i,:,:], cmap='RdBu_r', vmax=1, vmin=0)\n",
    "        plt.title(\"t = \" + str(i) + \"s\")        \n",
    "        \n",
    "        divider = make_axes_locatable(axh)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "        \n",
    "        plt.savefig(general_directory + \"/heatmap_frames/heatmap_\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "        \n",
    "    heatim = []\n",
    "    for i in range(0, nofrm-1, npstep):\n",
    "        heatim.append(imageio.imread(general_directory + \"/heatmap_frames/heatmap_\"\n",
    "                                     + str(i) + \".png\"))\n",
    "    imageio.mimsave((general_directory + \"/heatmap_frames/heatmap.gif\"), heatim)\n",
    "                          \n",
    "for c, param in enumerate(pkl_param):\n",
    "    import imageio\n",
    "    from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "    print('\\n')\n",
    "    print('Processing data via pure numpy method: ')\n",
    "    print('\\n')\n",
    "    df_to_numpy(data_dirs[c])\n",
    "    print('\\n')\n",
    "    print('Done!')\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
